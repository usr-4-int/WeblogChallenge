{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional questions for Machine Learning Engineer (MLE) candidates\n",
    "1. Predict the expected load (requests/second) in the next minute <br>\n",
    "2. Predict the session length for a given IP<br>\n",
    "3. Predict the number of unique URL visits by a given IP<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.functions import col, countDistinct\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import lit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Predictive Analytics\") \\\n",
    "    .config(\"spark.executor.memory\", \"1gb\") \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read log file\n",
    "rdd = sc.textFile('/Users/NK/Projects/pytm/2015_07_22_mktplace_shop_web_log_sample.log')\n",
    "# split by \" \"\n",
    "rdd = rdd.map(lambda line: line.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------+--------------------+\n",
      "|      ipaddress|                link|           timestamp|\n",
      "+---------------+--------------------+--------------------+\n",
      "|123.242.248.130|https://paytm.com...|2015-07-22T09:00:...|\n",
      "|  203.91.211.44|https://paytm.com...|2015-07-22T09:00:...|\n",
      "|    1.39.32.179|https://paytm.com...|2015-07-22T09:00:...|\n",
      "| 180.179.213.94|https://paytm.com...|2015-07-22T09:00:...|\n",
      "| 120.59.192.208|https://paytm.com...|2015-07-22T09:00:...|\n",
      "+---------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Keep timestamp, ip and link \n",
    "# convert the RDD to DF \n",
    "df = rdd.map(lambda line: Row(timestamp=line[0], ipaddress=line[2].split(':')[0], link=line[12])).toDF()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Predict the expected load (requests/second) in the next minute \n",
    "time range = 60 seconds <br>\n",
    "convert to datetime type <br>\n",
    "create 60 sec time range <br>\n",
    "groupby time_range <br>\n",
    "hit/Ip rate calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------------+--------------------+\n",
      "|          time_range|           timestamp|      ipaddress|                link|\n",
      "+--------------------+--------------------+---------------+--------------------+\n",
      "|[2015-07-22 05:00...|2015-07-22 05:00:...|123.242.248.130|https://paytm.com...|\n",
      "|[2015-07-22 05:00...|2015-07-22 05:00:...|  203.91.211.44|https://paytm.com...|\n",
      "|[2015-07-22 05:00...|2015-07-22 05:00:...|    1.39.32.179|https://paytm.com...|\n",
      "|[2015-07-22 05:00...|2015-07-22 05:00:...| 180.179.213.94|https://paytm.com...|\n",
      "|[2015-07-22 05:00...|2015-07-22 05:00:...| 120.59.192.208|https://paytm.com...|\n",
      "+--------------------+--------------------+---------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('timestamp', df['timestamp'].cast(TimestampType()))\n",
    "df_range = df.select(window(\"timestamp\", \"60 seconds\").alias('time_range'),'timestamp',\"ipaddress\",\"link\")\n",
    "df_range.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+--------------------+\n",
      "|summary|   ipaddress|                link|\n",
      "+-------+------------+--------------------+\n",
      "|  count|     1158500|             1158500|\n",
      "|   mean|        null|                null|\n",
      "| stddev|        null|                null|\n",
      "|    min|1.186.101.79|http://123.249.24...|\n",
      "|    max|  99.8.170.3|https://www.paytm...|\n",
      "+-------+------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_range.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-----+\n",
      "|time_range                                |count|\n",
      "+------------------------------------------+-----+\n",
      "|[2015-07-22 12:11:00, 2015-07-22 12:12:00]|24120|\n",
      "|[2015-07-22 07:57:00, 2015-07-22 07:58:00]|21   |\n",
      "|[2015-07-22 11:51:00, 2015-07-22 11:52:00]|9    |\n",
      "|[2015-07-22 06:34:00, 2015-07-22 06:35:00]|20915|\n",
      "|[2015-07-22 14:04:00, 2015-07-22 14:05:00]|16340|\n",
      "+------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of hits per time range regardless of ipaddress\n",
    "hit_per_timerange = df_range.groupBy('time_range').count()\n",
    "hit_per_timerange.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename count column \n",
    "hit_per_timerange = hit_per_timerange.withColumnRenamed('count', 'hit_min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+-------+\n",
      "|time_range                                |hit_min|\n",
      "+------------------------------------------+-------+\n",
      "|[2015-07-21 22:40:00, 2015-07-21 22:41:00]|4681   |\n",
      "|[2015-07-21 22:41:00, 2015-07-21 22:42:00]|6787   |\n",
      "|[2015-07-21 22:42:00, 2015-07-21 22:43:00]|5586   |\n",
      "|[2015-07-21 22:43:00, 2015-07-21 22:44:00]|4734   |\n",
      "|[2015-07-21 22:44:00, 2015-07-21 22:45:00]|4680   |\n",
      "+------------------------------------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort bt time_range\n",
    "sorted_hit_per_timerange = hit_per_timerange.orderBy('time_range', ascending=True)\n",
    "sorted_hit_per_timerange.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get id for each window\n",
    "Features = sorted_hit_per_timerange.withColumn(\"hit_sec\", col(\"hit_min\")/60.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+-----------+\n",
      "|          time_range|hit_min|             hit_sec|         Id|\n",
      "+--------------------+-------+--------------------+-----------+\n",
      "|[2015-07-21 22:40...|   4681|   78.01666666666667|          0|\n",
      "|[2015-07-21 22:41...|   6787|  113.11666666666666| 8589934592|\n",
      "|[2015-07-21 22:42...|   5586|                93.1|17179869184|\n",
      "|[2015-07-21 22:43...|   4734|                78.9|25769803776|\n",
      "|[2015-07-21 22:44...|   4680|                78.0|34359738368|\n",
      "|[2015-07-21 22:45...|    323|   5.383333333333334|42949672960|\n",
      "|[2015-07-22 01:09...|      1|0.016666666666666666|51539607552|\n",
      "|[2015-07-22 01:10...|  10099|  168.31666666666666|60129542144|\n",
      "|[2015-07-22 01:11...|  11670|               194.5|68719476736|\n",
      "|[2015-07-22 01:12...|  12255|              204.25|77309411328|\n",
      "+--------------------+-------+--------------------+-----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import monotonically_increasing_id \n",
    "#Features = Features.select(\"*\").withColumn(\"Id\", monotonically_increasing_id())\n",
    "Features.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "### - Date Time Features\n",
    "Date Time Features: these are components of the time step itself for each observation. <br>\n",
    "### - Lag Features\n",
    "Lag Features: these are values at prior time steps. <br>\n",
    "### - Rolling Window Statistics\n",
    "Window Features: these are a summary of values over a fixed window of prior time steps.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Window1= Window.orderBy(\"time_range\").rowsBetween(1,1)\n",
    "Window0= Window.orderBy(\"time_range\").rowsBetween(0,1)\n",
    "avg_hit_sec = avg(Features['hit_sec']).over(Window1)\n",
    "min_hit_sec = min(Features['hit_sec']).over(Window0)\n",
    "max_hit_sec = max(Features['hit_sec']).over(Window0)\n",
    "mean_hit_sec = mean(Features['hit_sec']).over(Window0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "|          time_range|             hit_sec|                  F1|                F2|                F3|     hit_in_next_min|\n",
      "+--------------------+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "|[2015-07-21 22:40...|   78.01666666666667|   78.01666666666667|113.11666666666666| 95.56666666666666|  113.11666666666666|\n",
      "|[2015-07-21 22:41...|  113.11666666666666|                93.1|113.11666666666666|103.10833333333332|                93.1|\n",
      "|[2015-07-21 22:42...|                93.1|                78.9|              93.1|              86.0|                78.9|\n",
      "|[2015-07-21 22:43...|                78.9|                78.0|              78.9|             78.45|                78.0|\n",
      "|[2015-07-21 22:44...|                78.0|   5.383333333333334|              78.0| 41.69166666666667|   5.383333333333334|\n",
      "|[2015-07-21 22:45...|   5.383333333333334|0.016666666666666666| 5.383333333333334|               2.7|0.016666666666666666|\n",
      "|[2015-07-22 01:09...|0.016666666666666666|0.016666666666666666|168.31666666666666| 84.16666666666667|  168.31666666666666|\n",
      "|[2015-07-22 01:10...|  168.31666666666666|  168.31666666666666|             194.5|181.40833333333333|               194.5|\n",
      "|[2015-07-22 01:11...|               194.5|               194.5|            204.25|           199.375|              204.25|\n",
      "|[2015-07-22 01:12...|              204.25|              204.25|            241.05|            222.65|              241.05|\n",
      "+--------------------+--------------------+--------------------+------------------+------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Features_target = Features.select(Features['time_range'], Features['hit_sec'],\n",
    "                                  min_hit_sec.alias(\"F1\"), max_hit_sec.alias(\"F2\"),mean_hit_sec.alias(\"F3\"),\n",
    "                                  avg_hit_sec.alias(\"hit_in_next_min\"))\n",
    "Features_target.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time_range: struct (nullable = false)\n",
      " |    |-- start: timestamp (nullable = true)\n",
      " |    |-- end: timestamp (nullable = true)\n",
      " |-- hit_sec: double (nullable = true)\n",
      " |-- F1: double (nullable = true)\n",
      " |-- F2: double (nullable = true)\n",
      " |-- F3: double (nullable = true)\n",
      " |-- hit_in_next_min: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Features_target.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit_sec</th>\n",
       "      <td>110</td>\n",
       "      <td>175.53030303030303</td>\n",
       "      <td>153.99226406331138</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "      <td>440.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>110</td>\n",
       "      <td>137.06893939393942</td>\n",
       "      <td>143.92251310400198</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "      <td>401.5833333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>110</td>\n",
       "      <td>213.65590909090906</td>\n",
       "      <td>154.3774496161323</td>\n",
       "      <td>0.03333333333333333</td>\n",
       "      <td>440.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>110</td>\n",
       "      <td>175.36242424242423</td>\n",
       "      <td>142.21541791932123</td>\n",
       "      <td>0.025</td>\n",
       "      <td>421.26666666666665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit_in_next_min</th>\n",
       "      <td>109</td>\n",
       "      <td>176.4249235474006</td>\n",
       "      <td>154.41610897182733</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "      <td>440.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                   1                   2  \\\n",
       "summary          count                mean              stddev   \n",
       "hit_sec            110  175.53030303030303  153.99226406331138   \n",
       "F1                 110  137.06893939393942  143.92251310400198   \n",
       "F2                 110  213.65590909090906   154.3774496161323   \n",
       "F3                 110  175.36242424242423  142.21541791932123   \n",
       "hit_in_next_min    109   176.4249235474006  154.41610897182733   \n",
       "\n",
       "                                    3                   4  \n",
       "summary                           min                 max  \n",
       "hit_sec          0.016666666666666666              440.95  \n",
       "F1               0.016666666666666666   401.5833333333333  \n",
       "F2                0.03333333333333333              440.95  \n",
       "F3                              0.025  421.26666666666665  \n",
       "hit_in_next_min  0.016666666666666666              440.95  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features_target.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# REMOVE NULL VALUES\n",
    "Features_target = Features_target.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit_sec</th>\n",
       "      <td>109</td>\n",
       "      <td>176.7637614678899</td>\n",
       "      <td>154.15668055485474</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "      <td>440.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>109</td>\n",
       "      <td>137.9495412844037</td>\n",
       "      <td>144.289267848117</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "      <td>401.5833333333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F2</th>\n",
       "      <td>109</td>\n",
       "      <td>215.23914373088684</td>\n",
       "      <td>154.1907413864437</td>\n",
       "      <td>0.03333333333333333</td>\n",
       "      <td>440.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F3</th>\n",
       "      <td>109</td>\n",
       "      <td>176.59434250764525</td>\n",
       "      <td>142.28145164642547</td>\n",
       "      <td>0.025</td>\n",
       "      <td>421.26666666666665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hit_in_next_min</th>\n",
       "      <td>109</td>\n",
       "      <td>176.4249235474006</td>\n",
       "      <td>154.41610897182733</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "      <td>440.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                   1                   2  \\\n",
       "summary          count                mean              stddev   \n",
       "hit_sec            109   176.7637614678899  154.15668055485474   \n",
       "F1                 109   137.9495412844037    144.289267848117   \n",
       "F2                 109  215.23914373088684   154.1907413864437   \n",
       "F3                 109  176.59434250764525  142.28145164642547   \n",
       "hit_in_next_min    109   176.4249235474006  154.41610897182733   \n",
       "\n",
       "                                    3                   4  \n",
       "summary                           min                 max  \n",
       "hit_sec          0.016666666666666666              440.95  \n",
       "F1               0.016666666666666666   401.5833333333333  \n",
       "F2                0.03333333333333333              440.95  \n",
       "F3                              0.025  421.26666666666665  \n",
       "hit_in_next_min  0.016666666666666666              440.95  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"time_range\" is not required for analysis\n",
    "Features_target_s = Features_target.drop (\"time_range\")\n",
    "Features_target_s.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Correlation to hit_in_next_min for ', 'hit_sec', 0.7033871078152598)\n",
      "('Correlation to hit_in_next_min for ', 'F1', 0.888602586524289)\n",
      "('Correlation to hit_in_next_min for ', 'F2', 0.8720443352929288)\n",
      "('Correlation to hit_in_next_min for ', 'F3', 0.9229445782978808)\n",
      "('Correlation to hit_in_next_min for ', 'hit_in_next_min', 1.0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import six\n",
    "for i in Features_target_s.columns:\n",
    "    if not( isinstance(Features_target_s.select(i).take(1)[0][0], six.string_types)):\n",
    "        print( \"Correlation to hit_in_next_min for \", i, Features_target_s.stat.corr('hit_in_next_min',i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            features|   hit_in_next_min|\n",
      "+--------------------+------------------+\n",
      "|[78.0166666666666...|113.11666666666666|\n",
      "|[113.116666666666...|              93.1|\n",
      "|[93.1,78.9,93.1,8...|              78.9|\n",
      "+--------------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = ['hit_sec', 'F1', 'F2', 'F3'], outputCol = 'features')\n",
    "vfeatures_df = vectorAssembler.transform(Features_target_s)\n",
    "vfeatures_df = vfeatures_df.select(['features', 'hit_in_next_min'])\n",
    "vfeatures_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splits = vfeatures_df.randomSplit([0.7, 0.3])\n",
    "train_df = splits[0]\n",
    "test_df = splits[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.981349941554299,0.6404834977003858,0.6372013072833304,0.7031158193211009]\n",
      "Intercept: 0.201502195949\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='hit_in_next_min', maxIter=10, regParam=0.3)\n",
    "lr_model = lr.fit(train_df)\n",
    "# Print the coefficients and intercept for linear regression model\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.140578\n",
      "r2: 0.999949\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model over the training set and print out some metrics\n",
    "trainingSummary = lr_model.summary\n",
    "print(\"RMSE: %f\" % trainingSummary.rootMeanSquaredError)\n",
    "print(\"r2: %f\" % trainingSummary.r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient Standard Errors: [0.002346198936135336, 0.00943586490329917, 0.00943386066606993, 0.01855189515439349, 0.2545809332533291]\n",
      "T Values: [-418.27226431650365, 67.87756122668164, 67.54406598086669, 37.899945718191915, 0.791505449266184]\n",
      "P Values: [0.0, 0.0, 0.0, 0.0, 0.43157283292268445]\n"
     ]
    }
   ],
   "source": [
    "print(\"Coefficient Standard Errors: \" + str(trainingSummary.coefficientStandardErrors))\n",
    "print(\"T Values: \" + str(trainingSummary.tValues))\n",
    "print(\"P Values: \" + str(trainingSummary.pValues))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|summary|     hit_in_next_min|\n",
      "+-------+--------------------+\n",
      "|  count|                  69|\n",
      "|   mean|  180.95217391304345|\n",
      "| stddev|  160.39693058916941|\n",
      "|    min|0.016666666666666666|\n",
      "|    max|              440.95|\n",
      "+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+--------------------+\n",
      "|         prediction|     hit_in_next_min|            features|\n",
      "+-------------------+--------------------+--------------------+\n",
      "| 164.68177612566063|              166.35|[0.01666666666666...|\n",
      "|  166.6263359189836|  168.31666666666666|[0.01666666666666...|\n",
      "| 189.28540130728084|  191.23333333333332|[0.01666666666666...|\n",
      "|0.21828319525161566|0.016666666666666666|[0.03333333333333...|\n",
      "|  160.4962069650283|  162.11666666666667|[0.03333333333333...|\n",
      "+-------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "R Squared (R2) on test data = 0.999947\n"
     ]
    }
   ],
   "source": [
    "# Predictions\n",
    "lr_predictions = lr_model.transform(test_df)\n",
    "lr_predictions.select(\"prediction\",\"hit_in_next_min\",\"features\").show(5)\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "lr_evaluator = RegressionEvaluator(predictionCol=\"prediction\", \\\n",
    "                 labelCol=\"hit_in_next_min\",metricName=\"r2\")\n",
    "print(\"R Squared (R2) on test data = %g\" % lr_evaluator.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 1.04584\n"
     ]
    }
   ],
   "source": [
    "test_result = lr_model.evaluate(test_df)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % test_result.rootMeanSquaredError)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+\n",
      "|        prediction|     hit_in_next_min|            features|\n",
      "+------------------+--------------------+--------------------+\n",
      "|205.68333333333337|              166.35|[0.01666666666666...|\n",
      "|205.68333333333337|  168.31666666666666|[0.01666666666666...|\n",
      "|205.68333333333337|  191.23333333333332|[0.01666666666666...|\n",
      "|             67.25|0.016666666666666666|[0.03333333333333...|\n",
      "|205.68333333333337|  162.11666666666667|[0.03333333333333...|\n",
      "+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'hit_in_next_min')\n",
    "dt_model = dt.fit(train_df)\n",
    "dt_predictions = dt_model.transform(test_df)\n",
    "dt_predictions.select('prediction', 'hit_in_next_min', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 40.9492\n"
     ]
    }
   ],
   "source": [
    "dt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"hit_in_next_min\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = dt_evaluator.evaluate(dt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(4, {0: 0.0442, 1: 0.0297, 2: 0.0501, 3: 0.876})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The most important feature: \n",
    "dt_model.featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient-boosted tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+--------------------+\n",
      "|        prediction|     hit_in_next_min|            features|\n",
      "+------------------+--------------------+--------------------+\n",
      "|208.68233932001274|              166.35|[0.01666666666666...|\n",
      "|208.68233932001274|  168.31666666666666|[0.01666666666666...|\n",
      "|208.68233932001274|  191.23333333333332|[0.01666666666666...|\n",
      "| 67.10159959983535|0.016666666666666666|[0.03333333333333...|\n",
      "| 206.1692497878579|  162.11666666666667|[0.03333333333333...|\n",
      "+------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'hit_in_next_min', maxIter=10)\n",
    "gbt_model = gbt.fit(train_df)\n",
    "gbt_predictions = gbt_model.transform(test_df)\n",
    "gbt_predictions.select('prediction', 'hit_in_next_min', 'features').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 39.83\n"
     ]
    }
   ],
   "source": [
    "gbt_evaluator = RegressionEvaluator(\n",
    "    labelCol=\"hit_in_next_min\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = gbt_evaluator.evaluate(gbt_predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
